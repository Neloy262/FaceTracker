{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import dlib\n",
    "import time\n",
    "import uuid\n",
    "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
    "import torch \n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cpu' if torch.cuda.is_available() else 'cpu')\n",
    "resnet = InceptionResnetV1(pretrained='vggface2').eval().to(device)\n",
    "MaxDist=100\n",
    "mtcnn = MTCNN(\n",
    "    image_size=160, margin=0, min_face_size=20,\n",
    "    thresholds=[0.6, 0.7, 0.7], factor=0.709, post_process=True,\n",
    "    device=device\n",
    ")\n",
    "print('Running on device: {}'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "database = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = transforms.ToTensor()\n",
    "\n",
    "Mahmud = cv2.imread(\"4.jpg\")\n",
    "pil_frame = cv2.cvtColor(Mahmud,cv2.COLOR_BGR2RGB)\n",
    "pil_frame = Image.fromarray(pil_frame)\n",
    "bbox_array,confidence = mtcnn.detect(pil_frame)\n",
    "(sX,sY,eX,eY) = bbox_array[0]\n",
    "h = eY - sY\n",
    "w = eX - sX\n",
    "Mahmud = Mahmud[int(sY):int(sY)+int(h), int(sX):int(sX)+int(w),:]\n",
    "Mahmud = cv2.resize(Mahmud,(160,160))\n",
    "Mahmud = trans(Mahmud)\n",
    "Mahmud = torch.unsqueeze(Mahmud,0).to(device)\n",
    "\n",
    "Mahmud2 = cv2.imread(\"3.jpg\")\n",
    "pil_frame = cv2.cvtColor(Mahmud2,cv2.COLOR_BGR2RGB)\n",
    "pil_frame = Image.fromarray(pil_frame)\n",
    "bbox_array,confidence = mtcnn.detect(pil_frame)\n",
    "(sX,sY,eX,eY) = bbox_array[0]\n",
    "h = eY - sY\n",
    "w = eX - sX\n",
    "Mahmud2 = Mahmud2[int(sY):int(sY)+int(h), int(sX):int(sX)+int(w),:]\n",
    "Mahmud2 = cv2.resize(Mahmud2,(160,160))\n",
    "Mahmud2 = trans(Mahmud2)\n",
    "Mahmud2 = torch.unsqueeze(Mahmud2,0).to(device)\n",
    "\n",
    "Monsur = cv2.imread(\"1.jpeg\")\n",
    "pil_frame = cv2.cvtColor(Monsur,cv2.COLOR_BGR2RGB)\n",
    "pil_frame = Image.fromarray(pil_frame)\n",
    "bbox_array,confidence = mtcnn.detect(pil_frame)\n",
    "(sX,sY,eX,eY) = bbox_array[0]\n",
    "h = eY - sY\n",
    "w = eX - sX\n",
    "Monsur = Monsur[int(sY):int(sY)+int(h), int(sX):int(sX)+int(w),:]\n",
    "Monsur = cv2.resize(Monsur,(160,160))\n",
    "Monsur = trans(Monsur)\n",
    "Monsur = torch.unsqueeze(Monsur,0).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mahmud = resnet(Mahmud)\n",
    "Monsur = resnet(Monsur)\n",
    "Mahmud2 = resnet(Mahmud2)\n",
    "\n",
    "database[Mahmud] = \"Mahmud\"\n",
    "database[Monsur] = \"Monsur\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Track():\n",
    "    def __init__(self,bbox,embeddings,confidence,tracker):\n",
    "        self.box=bbox\n",
    "        self.embeddings=embeddings\n",
    "        self.confidence=confidence\n",
    "        self.recognized=False\n",
    "        self.name=None\n",
    "        self.tracker=tracker\n",
    "        \n",
    "        \n",
    "    def start_track(self,frame,drect):\n",
    "        self.tracker.start_track(frame,drect)\n",
    "        \n",
    "    def update_track(self,new_box=None,new_confidence=None,new_label=None,_tracker=None):\n",
    "        self.box=new_box\n",
    "        self.tracker=_tracker if _tracker is not None else self.tracker \n",
    "        self.centroid=self.get_centroid()\n",
    "        \n",
    "    def checkDatabase(self):\n",
    "        global database,frame\n",
    "        flag = 0\n",
    "        (sX,sY,eX,eY) = self.box\n",
    "        \n",
    "        if sX<0 or eX>640 or sY<0 or eY>480:\n",
    "            return\n",
    "            \n",
    "        h = eY - sY\n",
    "        w = eX - sX\n",
    "        opencv_frame = frame[int(sY):int(sY)+int(h), int(sX):int(sX)+int(w),:]\n",
    "        opencv_frame = cv2.resize(opencv_frame,(160,160))\n",
    "        t1 = transforms.ToTensor()\n",
    "        crop_img = t1(opencv_frame)\n",
    "        crop_img = torch.unsqueeze(crop_img, 0)\n",
    "        crop_img = crop_img.permute((0, 1, 2, 3)).to(device)\n",
    "        self.embeddings = resnet(crop_img)\n",
    "        mindist = 100\n",
    "        name = \"\"\n",
    "        for key,value in database.items():\n",
    "            dist = (self.embeddings - key).norm().item()\n",
    "            if dist<mindist:\n",
    "                mindist = dist\n",
    "                name = value\n",
    "                self.name = name\n",
    "        if mindist<1:\n",
    "            flag = 1\n",
    "            self.name = name\n",
    "            \n",
    "        return flag\n",
    "    def get_centroid(self):\n",
    "        return (int((self.box[0]+self.box[2])/2),int((self.box[1]+self.box[3])/2))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ObjectCount():\n",
    "    def __init__(self):\n",
    "        self.gone_count = dict()\n",
    "            \n",
    "    def increment_gone_count(self,tracker):\n",
    "        self.gone_count[tracker]=self.gone_count.get(tracker,0)+1\n",
    "    \n",
    "    def get_gone_count(self,tracker):\n",
    "        return self.gone_count.get(tracker,0)\n",
    "    \n",
    "    def set_gone_count(self,tracker):\n",
    "        self.gone_count[tracker] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete(trackers,rects):\n",
    "    t = None\n",
    "    minDist = -100\n",
    "    for tracker in trackers:\n",
    "        centX,centY = tracker.get_centroid() \n",
    "        for rect in rects:\n",
    "            (sX,sY,eX,eY)=rect\n",
    "            centX_r=int((sX+eX)/2)\n",
    "            centY_r=int((sY+eY)/2)\n",
    "            manDist=abs(centX-centX_r)+abs(centY-centY_r)\n",
    "            \n",
    "            if manDist>minDist:\n",
    "                minDist = manDist\n",
    "                t = tracker\n",
    "    trackers.remove(t)\n",
    "    return trackers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "val = \"Not recognized\"\n",
    "frame_skip = 5\n",
    "frame_count = 0\n",
    "trackers = []\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "object_counter = ObjectCount()\n",
    "out = cv2.VideoWriter('output_1hr_vid.mp4',cv2.VideoWriter_fourcc('M','J','P','G'), fps, (640,480))\n",
    "while True:\n",
    "    \n",
    "    ret,frame = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        print(\"Video ended\")\n",
    "        break\n",
    "    pil_frame = cv2.cvtColor(frame,cv2.COLOR_BGR2RGB)\n",
    "    pil_frame = Image.fromarray(pil_frame)\n",
    "\n",
    "    if frame_count % frame_skip ==0:\n",
    "        bbox_array,confidence = mtcnn.detect(pil_frame)\n",
    "        \n",
    "        if bbox_array is not None:\n",
    "            bbox_confidence_list = list(zip(bbox_array,confidence))\n",
    "        \n",
    "            for (rect,conf) in bbox_confidence_list:\n",
    "                (sX,sY,eX,eY)=rect\n",
    "                centX_r=int((sX+eX)/2)\n",
    "                centY_r=int((sY+eY)/2)\n",
    "                flag=0\n",
    "                for i in trackers:\n",
    "\n",
    "                    centX,centY = i.get_centroid() \n",
    "\n",
    "\n",
    "                    manDist=abs(centX-centX_r)+abs(centY-centY_r) #Calculating manhattan distance\n",
    "                    if manDist<MaxDist:\n",
    "                        flag=1\n",
    "                        break\n",
    "\n",
    "                if flag!=1:\n",
    "#                     if sX<0 or eX>640 or sY<0 or eY>480:\n",
    "#                         continue\n",
    "#                     h = eY - sY\n",
    "#                     w = eX - sX\n",
    "#                     opencv_frame = frame[int(sY):int(sY)+int(h), int(sX):int(sX)+int(w),:]\n",
    "#                     opencv_frame = cv2.resize(opencv_frame,(160,160))\n",
    "#                     t1 = transforms.ToTensor()\n",
    "#                     crop_img = t1(opencv_frame)\n",
    "#                     crop_img = torch.unsqueeze(crop_img, 0)\n",
    "#                     crop_img = crop_img.permute((0, 1, 2, 3)).to(device)\n",
    "                    t = dlib.correlation_tracker()\n",
    "                    drect = dlib.rectangle(int(sX), int(sY), int(eX), int(eY))\n",
    "                    box=[int(sX),int(sY),int(eX),int(eY)]\n",
    "                    embeddings = None\n",
    "                    tracker = Track(box,embeddings,conf,t)\n",
    "                    tracker.start_track(frame, drect)\n",
    "                    trackers.append(tracker)\n",
    "                    object_counter.set_gone_count(tracker)\n",
    "#                     tracker.checkDatabase()\n",
    "            if cv2.waitKey(40) & 0xFF == ord('r'):\n",
    "                    for tracker in trackers:\n",
    "                        flag2 = tracker.checkDatabase()\n",
    "                        if flag2 == 1:\n",
    "                            val = \"Recognized\"\n",
    "                            \n",
    "            if len(trackers)>len(bbox_array):\n",
    "                trackers = delete(trackers,bbox_array)\n",
    "    \n",
    "    for t in trackers:\n",
    "#         trackers,bool_flag = delete(trackers,t)\n",
    "#         if bool_flag:\n",
    "#             continue\n",
    "        \n",
    "        sc = t.tracker.update(frame)\n",
    "        pos = t.tracker.get_position()\n",
    "        startX = int(pos.left())\n",
    "        startY = int(pos.top())\n",
    "        endX = int(pos.right())\n",
    "        endY = int(pos.bottom())\n",
    "\n",
    "        box=[startX,startY,endX,endY]\n",
    "        t.update_track(box)\n",
    "\n",
    "        centX,centY = t.get_centroid()\n",
    "        if endX>640 or startX<0: # If an object crosses the thresh line and the tracker value(sc) is below 12 remove it\n",
    "            object_counter.increment_gone_count(t)\n",
    "\n",
    "        # If gone count >= 5 update the object dictionary and remove the tracker\n",
    "        if object_counter.get_gone_count(t)>=5:\n",
    "            trackers.remove(t)\n",
    "            continue\n",
    "\n",
    "#         cv2.circle(frame,(centX,centY),10 , (0,0,255), -1)\n",
    "        cv2.rectangle(frame, (startX, startY), (endX, endY),(0, 255, 0), 2)\n",
    "        cv2.putText(frame, t.name, (centX,centY),cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
    "        \n",
    "    if val == \"Not recognized\":\n",
    "        cv2.putText(frame, val, (50,450),cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
    "    else:\n",
    "        cv2.putText(frame, val, (50,450),cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "    cv2.imshow(\"Frame\",frame)\n",
    "    out.write(frame)\n",
    "    frame_count+=1\n",
    "    if cv2.waitKey(20) & 0xFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "euclidena_dist = torch.cdist(Mahmud,Mahmud2)**2\n",
    "print(euclidena_dist.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
